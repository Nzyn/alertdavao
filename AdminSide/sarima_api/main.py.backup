
from fastapi import FastAPI, HTTPException, Body
from pydantic import BaseModel
from typing import List, Optional
import pandas as pd
import numpy as np
from statsmodels.tsa.statespace.sarimax import SARIMAX
import os
from datetime import datetime

# =========================================================
# FastAPI app
# =========================================================
app = FastAPI(
    title="SARIMA Crime Forecast API",
    description="Serves monthly crime forecasts from SARIMA(1,1,1)(1,1,1)[12] with live data support",
    version="2.0.0",
)

# =========================================================
# Pydantic models (for clean JSON responses)
# =========================================================
class MonthlyDataPoint(BaseModel):
    year: int
    month: int
    count: int

class TrainRequest(BaseModel):
    data: List[MonthlyDataPoint]

class ForecastItem(BaseModel):
    date: str
    forecast: float
    lower_ci: float
    upper_ci: float

class ForecastResponse(BaseModel):
    status: str
    horizon: int
    data: List[ForecastItem]
    trained_on_points: Optional[int] = None
    last_training: Optional[str] = None


ts = None              
sarima_model = None
last_training_time = None

def train_from_dataframe(df: pd.DataFrame):
    """Train SARIMA model from a pandas DataFrame with Year, Month, Count columns"""
    global ts, sarima_model, last_training_time

    # Create date column from Year and Month
    df['Date'] = pd.to_datetime(df[['Year', 'Month']].assign(day=1))
    df = df.sort_values('Date')
    
    # Create time series
    series = df.set_index('Date')['Count'].astype(float).sort_index()
    series = series.asfreq("MS")
    series = series.fillna(method="ffill")
    
    ts = series
    
    # Train SARIMA(1,1,1)(1,1,1)[12]
    model = SARIMAX(
        ts,
        order=(1, 1, 1),
        seasonal_order=(1, 1, 1, 12),
        enforce_stationarity=False,
        enforce_invertibility=False,
    )
    sarima_model = model.fit(disp=False)
    last_training_time = datetime.now().isoformat()
    
    print(f"‚úÖ SARIMA model trained on {len(ts)} observations at {last_training_time}")
    return len(ts)   
def load_and_train():
    """Load data from CSV file and train model (fallback/initial training)"""
    global ts, sarima_model

    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    # Try processed DCPO data first (5 years of historical data)
    csv_path = os.path.join(base_dir, "data", "CrimeDAta_Processed.csv")
    
    # Fallback to original CrimeDAta.csv if processed file doesn't exist
    if not os.path.exists(csv_path):
        csv_path = os.path.join(base_dir, "data", "CrimeDAta.csv")
    
    csv_path = os.path.abspath(csv_path)

    if not os.path.exists(csv_path):
        print(f"‚ö†Ô∏è CrimeDAta.csv not found at: {csv_path}")
        print("‚ö†Ô∏è Model will be trained when data is received via API")
        return

    df = pd.read_csv(csv_path)
    
    print(f"üìÇ Loading data from: {csv_path}")
    print(f"üìä Total rows: {len(df)}")

    cols_lower = [c.lower() for c in df.columns]

    # Check if already processed (has Year, Month, Count columns)
    if "year" in cols_lower and "month" in cols_lower and "count" in cols_lower:
        year_col = df.columns[cols_lower.index("year")]
        month_col = df.columns[cols_lower.index("month")]
        count_col = df.columns[cols_lower.index("count")]
        
        # Use Year, Month, Count format (already aggregated)
        df_clean = pd.DataFrame({
            'Year': pd.to_numeric(df[year_col], errors='coerce'),
            'Month': pd.to_numeric(df[month_col], errors='coerce'),
            'Count': pd.to_numeric(df[count_col], errors='coerce').fillna(0)
        })
        print(f"‚úÖ Using pre-aggregated data: {len(df_clean)} months of data")
    else:
        # Need to aggregate from raw data
        # Detect date column
        if "date" in cols_lower:
            date_col = df.columns[cols_lower.index("date")]
        elif "_date" in cols_lower:
            date_col = df.columns[cols_lower.index("_date")]
        else:
            date_col = df.columns[-1]

        # Detect count column
        if "count" in cols_lower:
            count_col = df.columns[cols_lower.index("count")]
        else:
            if df.shape[1] >= 3:
                count_col = df.columns[2]
            else:
                raise ValueError("Cannot find 'Count' column in CrimeDAta.csv")

        # Parse date column and aggregate
        df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
        df = df.dropna(subset=[date_col]).sort_values(date_col)
        df[count_col] = pd.to_numeric(df[count_col], errors="coerce").fillna(0)
        
        # Aggregate by year and month
        df['Year'] = df[date_col].dt.year
        df['Month'] = df[date_col].dt.month
        
        df_clean = df.groupby(['Year', 'Month'])[count_col].sum().reset_index()
        df_clean.columns = ['Year', 'Month', 'Count']
        print(f"‚úÖ Aggregated raw data into {len(df_clean)} months")
    
    df_clean = df_clean.dropna()
    print(f"üéØ Training SARIMA model on {len(df_clean)} months of historical data")
    print(f"   Date range: {df_clean['Year'].min()}-{df_clean['Month'].min():02d} to {df_clean['Year'].max()}-{df_clean['Month'].max():02d}")
    print(f"   Total crimes: {df_clean['Count'].sum():.0f}")
    
    train_from_dataframe(df_clean)


# =========================================================
# Run training once when the API starts
# =========================================================
@app.on_event("startup")
def startup_event():
    try:
        load_and_train()
    except Exception as e:
        # Log error to console; API will return 500 if not trained
        print("‚ùå Error during startup training:", e)


# =========================================================
# Routes
# =========================================================
@app.get("/", tags=["health"])
def health_check():
    """
    Simple health check endpoint.
    """
    trained = ts is not None and sarima_model is not None
    return {
        "status": "ok", 
        "message": "SARIMA API is running.",
        "model_trained": trained,
        "observations": len(ts) if ts is not None else 0,
        "last_training": last_training_time
    }


@app.post("/train", tags=["training"])
def train_model(request: TrainRequest):
    """
    Train or retrain the SARIMA model with live data from the database.
    Expects JSON: {"data": [{"year": 2024, "month": 1, "count": 45}, ...]}
    """
    try:
        if not request.data or len(request.data) < 24:
            raise HTTPException(
                status_code=400, 
                detail="Need at least 24 months of data for SARIMA training"
            )
        
        # Convert to DataFrame
        df = pd.DataFrame([{
            'Year': point.year,
            'Month': point.month,
            'Count': point.count
        } for point in request.data])
        
        # Train model
        num_points = train_from_dataframe(df)
        
        return {
            "status": "success",
            "message": f"Model trained successfully on {num_points} data points",
            "trained_on": num_points,
            "last_training": last_training_time
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Training failed: {str(e)}")


@app.get("/forecast", response_model=ForecastResponse, tags=["forecast"])
def get_forecast(horizon: int = 12):
    """
    Get next N months crime forecast.
    Default horizon = 12 months.
    """
    global ts, sarima_model

    if ts is None or sarima_model is None:
        raise HTTPException(
            status_code=500, 
            detail="Model not trained. Please send training data to /train endpoint first."
        )

    if horizon <= 0 or horizon > 60:
        raise HTTPException(status_code=400, detail="horizon must be between 1 and 60 months.")

    # Forecast
    forecast_res = sarima_model.get_forecast(steps=horizon)
    mean = forecast_res.predicted_mean
    ci = forecast_res.conf_int()

    future_dates = pd.date_range(
        start=ts.index[-1] + pd.DateOffset(months=1),
        periods=horizon,
        freq="MS",
    )

    items: List[ForecastItem] = []
    for i in range(horizon):
        items.append(
            ForecastItem(
                date=str(future_dates[i].date()),
                forecast=float(mean.iloc[i]),
                lower_ci=float(ci.iloc[i, 0]),
                upper_ci=float(ci.iloc[i, 1]),
            )
        )

    return ForecastResponse(
        status="success", 
        horizon=horizon, 
        data=items,
        trained_on_points=len(ts),
        last_training=last_training_time
    )
